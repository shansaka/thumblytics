{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utills import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/youtube_data_processed.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns that are not needed\n",
    "df = df.drop(['video_id', 'title', 'thumbnail_url', 'likes', 'comments', 'tags', 'category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull(), yticklabels=False, cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the missing values\n",
    "columns_to_fill = ['angry_emotion', 'disgust_emotion', 'fear_emotion', \n",
    "                   'happy_emotion', 'sad_emotion', 'surprise_emotion', \n",
    "                   'neutral_emotion']\n",
    "df[columns_to_fill] = df[columns_to_fill].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull(), yticklabels=False, cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Ensure 'date_posted' is in datetime format and make it timezone-naive\n",
    "df['date_posted'] = pd.to_datetime(df['date_posted'], errors='coerce')\n",
    "\n",
    "# Remove timezone information if it exists\n",
    "df['date_posted'] = df['date_posted'].dt.tz_localize(None)\n",
    "\n",
    "# Calculate the number of days since each video was posted\n",
    "df['days_since_posted'] = (datetime.now() - df['date_posted']).dt.days\n",
    "\n",
    "# Calculate Age-Weighted Views (AWV)\n",
    "df['age_weighted_views'] = df['views'] / (df['days_since_posted'] + 1)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [\n",
    "    0, \n",
    "    df['age_weighted_views'].quantile(0.10),  # Very Low (0 to 10th percentile)\n",
    "    df['age_weighted_views'].quantile(0.25),  # Low (10th to 25th percentile)\n",
    "    df['age_weighted_views'].quantile(0.75),  # Medium (25th to 75th percentile)\n",
    "    df['age_weighted_views'].quantile(0.90),  # High (75th to 90th percentile)\n",
    "    df['age_weighted_views'].max()            # Very High (90th percentile to max)\n",
    "]\n",
    "labels = [0, 1, 2, 3, 4]\n",
    "\n",
    "# Categorize 'age_weighted_views' into bins\n",
    "df['views_category'] = pd.cut(df['age_weighted_views'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Check the result\n",
    "df['views_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually check the counts of each category\n",
    "sns.countplot(x='views_category', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['date_posted', 'days_since_posted', 'age_weighted_views', 'views'], axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorzing colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply color categorization for the top 5 dominant colors\n",
    "for i in range(1, 6):\n",
    "    df[[f'dominant_color_{i}', f'dominant_color_{i}_name']] = df.apply(\n",
    "        lambda row: pd.Series(closest_color_name(\n",
    "            (row[f'color_{i}_r'], row[f'color_{i}_g'], row[f'color_{i}_b']))), axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['dominant_color_1', 'dominant_color_1_name', 'dominant_color_2', 'dominant_color_2_name']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['color_1_r', 'color_1_g','color_1_b', \n",
    "        'color_2_r', 'color_2_g', 'color_2_b', \n",
    "        'color_3_r','color_3_g', 'color_3_b', \n",
    "        'color_4_r', 'color_4_g', 'color_4_b',\n",
    "        'color_5_r', 'color_5_g', 'color_5_b' ], axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([ 'dominant_color_1_name',\n",
    "       'dominant_color_2_name', \n",
    "       'dominant_color_3_name',\n",
    "       'dominant_color_4_name',\n",
    "       'dominant_color_5_name'], axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with skewed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "df.select_dtypes(include=['number']).skew().plot(kind='bar', color='skyblue')\n",
    "plt.title('Skewness of Columns')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Skewness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewness_check(data):\n",
    "    total_left_skewed = 0\n",
    "    total_right_skewed = 0\n",
    "    for column in data.select_dtypes(include=['number']):\n",
    "        skewness = round(data[column].skew(), 3)\n",
    "    \n",
    "        # Checking if the skewness is between -1 and 1\n",
    "        if (skewness < -1):\n",
    "            print(f\"{column} : {skewness} (Left skewed)\")\n",
    "            total_left_skewed = total_left_skewed + 1\n",
    "        if (skewness > 1):\n",
    "            print(f\"{column} : {skewness} (Right skewed)\")\n",
    "            total_right_skewed = total_right_skewed + 1\n",
    "        \n",
    "    print(f'\\n')\n",
    "    print(f'Total skewed columns: {total_left_skewed + total_right_skewed}')\n",
    "    print(f'Total left skewed columns: {total_left_skewed}')\n",
    "    print(f'Total right skewed columns: {total_right_skewed}')\n",
    "\n",
    "skewness_check(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data):\n",
    "\n",
    "    # Getting a copy of the dataset, so we can return without changing original dataset\n",
    "    data_copy = data.copy()\n",
    "\n",
    "    for column in data_copy.select_dtypes(include=['number']):\n",
    "        skewness = round(data_copy[column].skew(), 3)\n",
    "        \n",
    "        # Checking if the skewness is between -1 and 1, \n",
    "        # because if it fit in that range we can use them without transforming\n",
    "        if (skewness < -1):\n",
    "            data_copy[column] = np.log1p(data_copy[column].abs())\n",
    "        if (skewness > 1):\n",
    "            data_copy[column] = np.sqrt(data_copy[column])\n",
    "        \n",
    "    print(f'Transformed completed.')\n",
    "    return data_copy\n",
    "\n",
    "\n",
    "# Transforming data to fix skewness of dataset columns\n",
    "transformed_data = transform_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rechecking skewness of transformed data\n",
    "skewness_check(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing visually before and after transformation, skewed fixed.\n",
    "def plot_before_after_transformation(original_data, transformed_data, title):\n",
    "\n",
    "    skewness_original = round(original_data.skew(), 2)\n",
    "    skewness_transformed = round(transformed_data.skew(), 2)\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "    axs[0].hist(original_data, edgecolor='black')\n",
    "    axs[0].set_title(f\"Before Transformation - {title}\")\n",
    "    axs[0].annotate(f\"Skewness: {skewness_original}\", xy=(0.5, 0.96), xycoords='axes fraction', ha='center')\n",
    "\n",
    "    axs[1].hist(transformed_data, edgecolor='black')\n",
    "    axs[1].set_title(f\"After Transformation - {title}\")\n",
    "    axs[1].annotate(f\"Skewness: {skewness_transformed}\", xy=(0.5, 0.96), xycoords='axes fraction', ha='center')\n",
    "    \n",
    "# Visualize the transformation for all the columns which are skewed\n",
    "def visualize_transformation(original_data, transformed_data):\n",
    "    for column in original_data.select_dtypes(include=['number']):\n",
    "        skewness = round(original_data[column].skew(), 3)\n",
    "\n",
    "        # Checking if the skewness is between -1 and 1\n",
    "        if (skewness < -1) | (skewness > 1):\n",
    "            plot_before_after_transformation(original_data[column], transformed_data[column], column)\n",
    "\n",
    "# Visualize the transformation\n",
    "visualize_transformation(df, transformed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing transform data into original data\n",
    "df = transformed_data\n",
    "\n",
    "# Rechecking skewness to make sure\n",
    "skewness_check(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "sns.boxplot(data=df, orient=\"h\")\n",
    "plt.title(\"Boxplot of Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fix_outliers(data):\n",
    "    # Getting a copy of the dataset, so we can return without changing original dataset\n",
    "    data_copy = data.copy()\n",
    "\n",
    "    print(f\"Before fixing outliers - Shape: {data_copy.shape}\")\n",
    "\n",
    "    # Select only numeric columns\n",
    "    numeric_columns = data_copy.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "    for column in numeric_columns:\n",
    "        # Calculate the IQR\n",
    "        IQR = data_copy[column].quantile(0.75) - data_copy[column].quantile(0.25)\n",
    "        lower_limit = data_copy[column].quantile(0.25) - (IQR * 1.5)\n",
    "        upper_limit = data_copy[column].quantile(0.75) + (IQR * 1.5)\n",
    "\n",
    "        # Clip the outliers\n",
    "        data_copy[column] = np.where(\n",
    "            data_copy[column] > upper_limit, upper_limit, \n",
    "            np.where(data_copy[column] < lower_limit, lower_limit, data_copy[column])\n",
    "        )\n",
    "        \n",
    "    print(f'Outliers fixed.')  \n",
    "    print(f\"After fixing outliers - Shape: {data_copy.shape}\") \n",
    "    return data_copy\n",
    "\n",
    "# Fixing outliers using IQR\n",
    "df_without_outliers = fix_outliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing visually before and after outlier fixed\n",
    "def plot_before_after_outlier_fix(original_data, transformed_data):\n",
    "    for column in original_data:\n",
    "        plt.figure(figsize=(10, 3))\n",
    "        plt.subplot(2, 1, 1)\n",
    "        sns.boxplot(data=original_data[column], orient=\"h\")\n",
    "        plt.title(f\"Before outlier fix - {column}\")\n",
    "\n",
    "        plt.subplot(2, 1, 2)\n",
    "        sns.boxplot(data=transformed_data[column], orient=\"h\")\n",
    "        plt.title(f\"After outlier fix - {column}\")\n",
    "        plt.tight_layout()        \n",
    "        plt.show()\n",
    "\n",
    "# Visualizing before and after fixing outliers\n",
    "plot_before_after_outlier_fix(df, df_without_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_without_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation matrix heatmap\n",
    "def plot_correlation_matrix_heatmap(data, threshold = 0):\n",
    "    correlation_matrix = data.corr().round(2)\n",
    "    \n",
    "    if threshold > 0:\n",
    "        # Apply the mask to the correlation matrix\n",
    "        correlation_matrix = correlation_matrix[np.abs(correlation_matrix) > threshold]\n",
    "\n",
    "    plt.figure(figsize=(18, 18)) \n",
    "    sns.heatmap(correlation_matrix, annot=True, linewidths=.5, fmt='.1f')\n",
    "    plt.title(\"Correlation Matrix Heatmap\")\n",
    "    plt.show()\n",
    "\n",
    "# Checking correlation between each feature\n",
    "plot_correlation_matrix_heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are lots of feature, Let's show only highly correlated ones only. So It's easier to understand. \n",
    "# Only showing correlation more than 0.7\n",
    "plot_correlation_matrix_heatmap(df, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see only emotion highly corelated with each other. but those feaures are emitoins so will keep those features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, precision_score, f1_score, recall_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# ML models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def save_model(model, filename):\n",
    "    # Ensure the directory exists\n",
    "    directory = '../model'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Save the model to disk\n",
    "    filename = directory + \"/\" + filename\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"Model saved to {filename}\")\n",
    "\n",
    "# Evaluate a ML model on the dataset\n",
    "def evaluate_model(model, data, features, target, is_save_model=False):\n",
    "    result = {}\n",
    "\n",
    "    # Setting X & y for the model\n",
    "    X = data[features]\n",
    "    y = data[target]\n",
    "\n",
    "    # Splitting the data for train and test, setting 25% of data to be test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "    # Fitting data to the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make prediction on the test set\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Model Evaluation Metrics\n",
    "    model_name = model.__class__.__name__\n",
    "    mse = round(mean_squared_error(y_test, predictions), 3)\n",
    "    accuracy = round(metrics.accuracy_score(y_test, predictions), 3)\n",
    "    precision = round(precision_score(y_test, predictions, average='weighted'), 3)\n",
    "    recall = round(recall_score(y_test, predictions, average='weighted'), 3)\n",
    "    f1 = round(f1_score(y_test, predictions, average='weighted'), 3)\n",
    "\n",
    "    # Checking if selected features are all the columns in the dataset\n",
    "    is_all_features = len(features) == (len(data.columns) - 1)\n",
    "\n",
    "    # Result dictionary\n",
    "    result = {\n",
    "        'Model': model_name, \n",
    "        'Accuracy': accuracy,\n",
    "        'Mean Squared Error': mse,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'All Features Used': is_all_features\n",
    "    }\n",
    "\n",
    "    print('Features Used')\n",
    "    print(features)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "    # Detailed Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    c_matrix = confusion_matrix(y_test, predictions)\n",
    "    sns.heatmap(c_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # Check if the model has feature importances and plot them\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feature_importances = model.feature_importances_\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': features,\n",
    "            'Importance': feature_importances\n",
    "        }).sort_values(by='Importance', ascending=False)\n",
    "        \n",
    "        # Plot feature importances\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "        plt.title(f'Feature Importance in {model_name}')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"The model {model_name} does not support feature importances.\")\n",
    "\n",
    "    # Save the model if needed\n",
    "    if is_save_model:\n",
    "        print(f\"Saving model to disk...\")\n",
    "        save_model(model, f'ytpa_model.pkl')\n",
    "\n",
    "    return result\n",
    "\n",
    "# Creating a list which holds each model's results\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = df.drop(columns='views_category').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(evaluate_model(RandomForestClassifier(), df, all_features, 'views_category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(evaluate_model(SVC(), df, all_features, 'views_category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(evaluate_model(LogisticRegression(), df, all_features, 'views_category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(evaluate_model(DecisionTreeClassifier(), df, all_features, 'views_category'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_drop_list =[\n",
    "    'views_category',\n",
    "    'disgust_emotion',\n",
    "    'is_text_present',\n",
    "]\n",
    "selected_features = df.drop(columns=column_drop_list).columns\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(evaluate_model(RandomForestClassifier(), df, selected_features, 'views_category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(evaluate_model(SVC(), df, selected_features, 'views_category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(evaluate_model(LogisticRegression(), df, selected_features, 'views_category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(evaluate_model(DecisionTreeClassifier(), df, selected_features, 'views_category'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data = pd.DataFrame(results)\n",
    "result_data.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_metrics(data, target_column, title):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    df_long = data.melt(id_vars=[target_column], var_name='Metric', value_name='Value')\n",
    "    sns.barplot(x='Model', y='Value', hue='Metric', data=df_long)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Values')\n",
    "    plt.legend(title='Metrics')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# visualizing metrics using bar plot\n",
    "plot_bar_metrics(result_data.drop(columns=\"All Features Used\"), 'Model', 'Model Metrics - Selected Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the results we can see Random Forest Classifier is the best model for this dataset, and we will use all the features since it doesnt apper to have effect when features are selected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(RandomForestClassifier(), df, selected_features, 'views_category', is_save_model=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
