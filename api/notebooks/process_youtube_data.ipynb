{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the YouTube data now...\n",
      "../data/youtube_data_processed.csv does not exist.\n",
      "\u001b[H\u001b[2JProcessing row 1 of 5...\n",
      "Downloading image from URL:  https://i.ytimg.com/vi/9J_BZG30GWo/maxresdefault.jpg\n",
      "\n",
      "0: 384x640 1 person, 6 books, 62.1ms\n",
      "Speed: 2.4ms preprocess, 62.1ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed row 2\n",
      "\u001b[H\u001b[2JProcessing row 2 of 5...\n",
      "Downloading image from URL:  https://i.ytimg.com/vi/ll8f05AeDys/maxresdefault.jpg\n",
      "\n",
      "0: 384x640 2 persons, 59.0ms\n",
      "Speed: 1.3ms preprocess, 59.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed row 3\n",
      "\u001b[H\u001b[2JProcessing row 3 of 5...\n",
      "Downloading image from URL:  https://i.ytimg.com/vi/L9QcQKbZUvk/maxresdefault.jpg\n",
      "\n",
      "0: 384x640 1 person, 52.4ms\n",
      "Speed: 1.3ms preprocess, 52.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed row 4\n",
      "\u001b[H\u001b[2JProcessing row 4 of 5...\n",
      "Downloading image from URL:  https://i.ytimg.com/vi/VBw0L-pYIHM/maxresdefault.jpg\n",
      "\n",
      "0: 384x640 1 person, 54.8ms\n",
      "Speed: 1.3ms preprocess, 54.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed row 5\n",
      "\u001b[H\u001b[2JProcessing row 5 of 5...\n",
      "Downloading image from URL:  https://i.ytimg.com/vi/vVpLHqd9QoU/maxresdefault.jpg\n",
      "\n",
      "0: 384x640 1 person, 1 clock, 49.4ms\n",
      "Speed: 1.6ms preprocess, 49.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed row 6\n",
      "\u001b[H\u001b[2JFeature extraction complete and saved to CSV.\n",
      "Total rows processed: 5 of 5\n",
      "Total errors: 0\n",
      "+------------+---------+\n",
      "| Video ID   | Error   |\n",
      "+============+=========+\n",
      "+------------+---------+\n",
      "Finished processing the YouTube data. Run the script again and choose 'Create model' to proceed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tabulate import tabulate\n",
    "import csv\n",
    "import platform\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Internal functions\n",
    "from utills import process_thumbnail\n",
    "\n",
    "\n",
    "def clear_console():\n",
    "    # Check the platform\n",
    "    current_os = platform.system()\n",
    "\n",
    "    if current_os == \"Windows\":\n",
    "        os.system('cls')\n",
    "    else:  # Linux and macOS\n",
    "        os.system('clear')\n",
    "\n",
    "# Main function to iterate through the dataset and save results to a CSV file\n",
    "def process_youtube_data(dataset):\n",
    "    error_log = []\n",
    "    total_rows = len(dataset)\n",
    "    processed_rows = 0\n",
    "\n",
    "    # Check if the file already exists to determine if headers should be written\n",
    "    file_exists = os.path.exists('../data/youtube_data_processed.csv')\n",
    "\n",
    "    file_path = '../data/youtube_data_processed.csv'\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "        print(f\"{file_path} has been removed.\")\n",
    "    else:\n",
    "        print(f\"{file_path} does not exist.\")\n",
    "\n",
    "    with open(file_path, mode='a', newline='', encoding='utf-8') as file:\n",
    "        # Initialize the CSV writer\n",
    "        writer = None\n",
    "\n",
    "        for index, row in dataset.iterrows():\n",
    "            clear_console()\n",
    "            print(f\"Processing row {processed_rows + 1} of {total_rows}...\")\n",
    "            row_data, error = process_thumbnail(row)\n",
    "            \n",
    "            if row_data:\n",
    "                if writer is None:\n",
    "                    # Write the header only if the file doesn't exist\n",
    "                    writer = csv.DictWriter(file, fieldnames=row_data.keys())\n",
    "                    if not file_exists:\n",
    "                        writer.writeheader()\n",
    "\n",
    "                # Write the processed row data\n",
    "                writer.writerow(row_data)\n",
    "                processed_rows += 1\n",
    "\n",
    "            if error:\n",
    "                error_log.append(error)\n",
    "\n",
    "            print(f\"Processed row {processed_rows + 1}\")\n",
    "\n",
    "    clear_console()\n",
    "\n",
    "    print(\"Feature extraction complete and saved to CSV.\")\n",
    "    print(f\"Total rows processed: {processed_rows} of {total_rows}\")\n",
    "    print(f\"Total errors: {len(error_log)}\")\n",
    "\n",
    "    # Convert the error log list into a list of lists for tabulate\n",
    "    table_data = [[entry['video_id'], entry['error']] for entry in error_log]\n",
    "\n",
    "    # Define headers\n",
    "    headers = ['Video ID', 'Error']\n",
    "\n",
    "    # Display the table using tabulate\n",
    "    print(tabulate(table_data, headers=headers, tablefmt='grid'))\n",
    "\n",
    "print(\"Processing the YouTube data now...\")\n",
    "dataset = pd.read_csv('../data/youtube_data.csv')\n",
    "\n",
    "# Sample 5 random rows from the dataset, comment this line to process the entire dataset\n",
    "dataset = dataset.sample(n=5, random_state=1) \n",
    "\n",
    "process_youtube_data(dataset)\n",
    "print(\"Finished processing the YouTube data. Run the script again and choose 'Create model' to proceed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
